%!TEX program = biber
%!TEX root = sloan_privacy_annualreport_2016-2017.tex

@TechReport{AbowdSchmutte2015,
  Title                    = {Revisiting the Economics of Privacy: Population Statistics and Confidentiality Protection as
Public Goods},
  Author                   = {John M. Abowd and Ian Schmutte},
  Institution              = {Labor Dynamics Institute, Cornell University},
  Year                     = {2016},
  Type                     = {Document},
  Number                   = {22},
  Url                      = {http://digitalcommons.ilr.cornell.edu/ldi/22/}
}

@TechReport{Abowd:Revisiting:LDI:2017,
  author      = {John M. Abowd and Schmutte, Ian M.},
  title       = {Revisiting the economics of privacy: {P}opulation statistics and confidentiality protection as public goods},
  institution = {Labor Dynamics Institute, Cornell University},
  year        = {2017},
  type        = {Document},
  number      = {37},
  doi         = {N/A},
  keywords    = {Economics of Privacy},
  owner       = {vilhuber},
  timestamp   = {2018.01.30},
  url         = {http://digitalcommons.ilr.cornell.edu/ldi/37/},
}

@Article{abowd:schmutte:BPEA:2015,
  author    = {John M. Abowd and Ian M. Schmutte},
  title     = {Economic analysis and statistical disclosure limitation},
  journal   = {Brookings Papers on Economic Activity},
  year      = {2015},
  pages     = {221--267},
  note      = {Spring},
  doi       = {10.1353/eca.2016.0004},
  keywords  = {Statistical Disclosure Limitation, SDL, primary},
  owner     = {John Abowd},
  timestamp = {2016.07.08},
  url       = {http://www.brookings.edu/~/media/Projects/BPEA/Spring-2015-Revised/AbowdText.pdf?la=en},
}

@Article{VilhuberAbowdReiter:Synthetic:SJIAOS:2016,
  author   = {Lars Vilhuber and John M. Abowd and Jerome P. Reiter},
  title    = {Synthetic establishment microdata around the world},
  journal  = {Statistical Journal of the International Association for Official Statistics},
  year     = {2016},
  volume   = {32},
  number   = {1},
  pages    = {65-68},
  abstract = {In contrast to the many public-use microdata samples available for individual and household data from many statistical agencies around the world, there are virtually no establishment or firm microdata available. In large part, this difficulty in providing access to business micro data is due to the skewed and sparse distributions that characterize business data. Synthetic data are simulated data generated from statistical models. We organized sessions at the 2015 World Statistical Congress and the 2015 Joint Statistical Meetings, highlighting work on synthetic establishment microdata. This overview situates those papers, published in this issue, within the broader literature.},
  doi      = {10.3233/SJI-160964},
  keywords = {statistical disclosure limitation, SDL},
  url      = {https://ecommons.cornell.edu/handle/1813/42340},
}

@Article{MirandaVilhuber:Using:SJIAOS:2016,
  author   = {Javier Miranda and Lars Vilhuber},
  title    = {Using partially synthetic microdata to protect sensitive cells in business statistics},
  journal  = {Statistical Journal of the International Association for Official Statistics},
  year     = {2016},
  volume   = {32},
  number   = {1},
  pages    = {69-80},
  abstract = {We describe and analyze a method that blends records from both observed and synthetic microdata into public-use tabulations on establishment statistics. The resulting tables use synthetic data only in potentially sensitive cells. We describe different algorithms, and present preliminary results when applied to the Census Bureau's Business Dynamics Statistics and Synthetic Longitudinal Business Database, highlighting accuracy and protection afforded by the method when compared to existing public-use tabulations (with suppressions).},
  doi      = {10.3233/SJI-160963},
  keywords = {statistical disclosure limitation, SDL},
  url      = {https://content.iospress.com/articles/statistical-journal-of-the-iaos/sji963},
}

@Article{Schmutte:Differentially:SJIAOS:2016,
  author   = {Ian M. Schmutte},
  title    = {{Differentially Private Release of Data on Wage and Job Mobility}},
  journal  = {Statistical Journal of the IAOS},
  year     = {2016},
  volume   = {32},
  number   = {1},
  pages    = {81-92},
  abstract = {Brazil, like many countries, is reluctant to publish business-level data, because of legitimate concerns about the establishments' confidentiality. A trusted data curator can increase the utility of data, while managing the risk to establishments, either by releasing synthetic data, or by infusing noise into published statistics. This paper evaluates the application of a differentially private mechanism to publish statistics on wages and job mobility computed from Brazilian employer-employee matched data. The publication mechanism can result in both the publication of specific statistics as well as the generation of synthetic data. I find that the tradeoff between the privacy guaranteed to individuals in the data, and the accuracy of published statistics, is potentially much better that the worst-case theoretical accuracy guarantee. However, the synthetic data fare quite poorly in analyses that are outside the set of queries to which it was trained. Note that this article only explores and characterizes the feasibility of these publication strategies, and will not directly result in the publication of any data.},
  doi      = {10.3233/SJI-160962},
  keywords = {formal privacy},
  url      = {https://content.iospress.com/articles/statistical-journal-of-the-iaos/sji962},
}

@TechReport{ProceedingsNSFSloan2016,
	Title                    = {Proceedings from the 2016 NSF-Sloan Workshop on Practical Privacy},
	Author                   = {Lars Vilhuber and Ian Schmutte},
	Institution              = {Labor Dynamics Institute, Cornell University},
	Year                     = {2017},
	Type                     = {Document},
	Number                   = {33},
	Url                      = {http://digitalcommons.ilr.cornell.edu/ldi/33/}
}

@Article{annalsSorting,
	author = {John M. Abowd and Francis Kramarz and Sebastien Perez-Duarte and Ian M. Schmutte},
	title = {Sorting Between and Within Industries: A Testable Model of Assortative Matching},
	journal = {Annals of Economics and Statistics},
	year = {2018},
	issn = {21154430, 19683863},
	__markedentry = {[vilhuber:6]},
	owner = {vilhuber},
	timestamp = {2017.09.21},
}

@techreport{Haney:LDI:2017,
	author = {Samuel Haney and Ashwin Machanavajjhala and John M. Abowd and Matthew Graham and Mark Kutzbach and Lars Vilhuber},
	title = {Utility Cost of Formal Privacy for Releasing National Employer-Employee Statistics},
	institution = {Labor Dynamics Institute, Cornell University},
	year = {2017},
	type = {Document},
	number = {36},
	 Url                      = {http://digitalcommons.ilr.cornell.edu/ldi/36/},
	abstract = {National statistical agencies around the world publish tabular summaries based on combined employer-employee (ER-EE) data. The privacy of both individuals and business establishments that feature in these data are protected by law in most countries. These data are currently released using a variety of statistical disclosure limitation (SDL) techniques that do not reveal the exact characteristics of particular employers and employees, but lack provable privacy guarantees limiting inferential disclosures.
	In this work, we present novel algorithms for releasing tabular summaries of linked ER-EE data with formal, provable guarantees of privacy. We show that state-of-the-art differentially private algorithms add too much noise for the output to be useful. Instead, we identify the privacy requirements mandated by current interpretations of the relevant laws, and formalize them using the Pufferfish framework. We then develop new privacy definitions that are customized to ER-EE data and satisfy the statutory privacy requirements. We implement the experiments in this paper on production data gathered by the U.S. Census Bureau. An empirical evaluation of utility for these data shows that for reasonable values of the privacy-loss parameter $\epsilon\geq$ 1, the additive error introduced by our provably private algorithms is comparable, and in some cases better, than the error introduced by existing SDL techniques that have no provable privacy guarantees. For some complex queries currently published, however, our algorithms do not have utility comparable to the existing traditional SDL algorithms. Those queries are fodder for future research.},
}

@InProceedings{HaneySIGMOD2017,
  author    = {Samuel Haney and Ashwin Machanavajjhala and John M. Abowd and Matthew Graham and Mark Kutzbach and Lars Vilhuber},
  title     = {Utility Cost of Formal Privacy for Releasing National Employer-Employee Statistics},
  booktitle = {Proceedings of the 2017 International Conference on Management of Data},
  year      = {2017},
  series    = {SIGMOD '17},
  publisher = {ACM},
  pages = {1339-1354},
  doi = {10.1145/3035918.3035940},
  acmid = {3035940},
  url = {http://doi.acm.org/10.1145/3035918.3035940},

  abstract  = {National statistical agencies around the world publish tabular summaries based on combined employer-employee (ER-EE) data. The privacy of both individuals and business establishments that feature in these data are protected by law in most countries. These data are currently released using a variety of statistical disclosure limitation (SDL) techniques that  do not reveal the exact characteristics of particular employers and employees, but lack provable privacy guarantees limiting inferential disclosures.

In this work, we present novel algorithms for releasing tabular summaries of linked ER-EE data with formal, provable guarantees of privacy. We show that state-of-the-art differentially private algorithms add too much noise for the output to be useful. Instead, we identify the privacy requirements mandated by current interpretations of the relevant laws, and formalize them using the Pufferfish framework. We then develop new privacy definitions that are customized to ER-EE data and satisfy the statutory privacy requirements. We implement the experiments in this paper on production data gathered by the U.S. Census Bureau. An empirical evaluation of utility for these data shows that for reasonable values of the privacy-loss parameter $\epsilon\geq$ 1, the additive error introduced by our provably private algorithms is comparable, and in some cases better, than the error introduced by existing SDL techniques that have no provable privacy guarantees. For some complex queries currently published, however, our algorithms do not have utility comparable to the existing traditional SDL algorithms. Those queries are fodder for future research.},
  acmid     = {3035940},
  journal   = {SIGMOD},
  owner     = {vilhuber},
  timestamp = {2017.03.01},
}

@Article{Abowd:JPC:2017,
	author = {John M. Abowd},
	title = {How Will Statistical Agencies Operate When All Data Are Private?},
	journal = {Journal of Privacy and Confidentiality},
	year = {2017},
	volume = {7},
	number = {3},
	abstract = {The dual problems of respecting citizen privacy and protecting the confidentiality of their data have become hopelessly conflated in the ?Big Data? era. There are orders of magnitude more data outside an agency?s firewall than inside it-compromising the integrity of traditional statistical disclosure limitation methods. And increasingly the information processed by the agency was ?asked? in a context wholly outside the agency?s operations-blurring the distinction between what was asked and what is published. Already, private businesses like Microsoft, Google and Apple recognize that cybersecurity (safeguarding the integrity and access controls for internal data) and privacy protection (ensuring that what is published does not reveal too much about any person or business) are two sides of the same coin. This is a paradigm-shifting moment for statistical agencies.},
	owner = {vilhuber},
	timestamp = {2017.05.03},
	url = {http://repository.cmu.edu/jpc/vol7/iss3/1/},
	pdf = {http://repository.cmu.edu/cgi/viewcontent.cgi?article=1142&context=jpc}
}


@article {chance:2017,
	title = {Making Confidential Data Part of Reproducible Research},
	journal = {Chance},
	year = {2017},
	month = {09/2017},
	url = {http://chance.amstat.org/2017/09/reproducible-research/},
	author = {Vilhuber, Lars and Lagoze, Carl}
}

@TechReport{ProceedingsNSFSloan2017,
	author = {Lars Vilhuber and Ian Schmutte},
	title = {Proceedings from the 2017 Cornell-Census-NSF-Sloan Workshop on Practical Privacy},
	institution = {Labor Dynamics Institute, Cornell University},
	year = {2017},
	type = {Document},
	number = {43},
	abstract = {These proceedings report on a workshop hosted at the U.S. Census Bureau on May 8, 2017. Our purpose was to gather experts from various backgrounds together to continue discussing the development of formal privacy systems for Census Bureau data products. This workshop was a successor to a previous workshop held in October 2016 (Vilhuber & Schmutte 2017). At our prior workshop, we hosted computer scientists, survey statisticians, and economists, all of whom were experts in data privacy. At that time we discussed the practical implementation of cutting-edge methods for publishing data with formal, provable privacy guarantees, with a focus on applications to Census Bureau data products. The teams developing those applications were just starting out when our first workshop took place, and we spent our time brainstorming solutions to the various problems researchers were encountering, or anticipated encountering. For these cutting-edge formal privacy models, there had been very little effort in the academic literature to apply those methods in real-world settings with large, messy data. We therefore brought together an expanded group of specialists from academia and government who could shed light on technical challenges, subject matter challenges and address how data users might react to changes in data availability and publishing standards.
	In May 2017, we organized a follow-up workshop, which these proceedings report on. We reviewed progress made in four different areas. The four topics discussed as part of the workshop were 1. the 2020 Decennial Census; 2. the American Community Survey (ACS); 3. the 2017 Economic Census; 4. measuring the demand for privacy and for data quality.
	As in our earlier workshop, our goals were to 1. Discuss the specific challenges that have arisen in ongoing efforts to apply formal privacy models to Census data products by drawing together expertise of academic and governmental researchers; 2. Produce short written memos that summarize concrete suggestions for practical applications to specific Census Bureau priority areas.},
	owner = {vilhuber},
	timestamp = {2017.09.28},
	url = {http://digitalcommons.ilr.cornell.edu/ldi/43/},
}

@TechReport{ProceedingsSynLBD2017,
	author = {Lars Vilhuber and Saki Kinney and Ian Schmutte},
	title = {Proceedings from the Synthetic LBD International Seminar},
	institution = {Labor Dynamics Institute, Cornell University},
	year = {2017},
	type = {Document},
	number = {44},
	abstract = {On May 9, 2017, we hosted a seminar to discuss the conditions necessary to implement the SynLBD approach with interested parties, with the goal of providing a straightforward toolkit to implement the same procedure on other data. The proceedings summarize the discussions during the workshop.},
	owner = {vilhuber},
	timestamp = {2017.09.22},
	url = {http://digitalcommons.ilr.cornell.edu/ldi/44/},
}

@TechReport{Abowd:LDI:37,
	author = {John M. Abowd and Ian M. Schmutte},
	title = {Revisiting the Economics of Privacy: Population Statistics and Confidentiality Protection as Public Goods},
	institution = {Labor Dynamics Institute},
	year = {2017},
	type = {Document},
	number = {37},
	month = {04/2017},
	abstract = {We consider the problem of determining the optimal accuracy of public statistics when increased accuracy requires a loss of privacy. To formalize this allocation problem, we use tools from statistics and computer science to model the publication technology used by a public statistical agency. We derive the demand for accurate statistics from first principles to generate interdependent preferences that account for the public-good nature of both data accuracy and privacy loss. We first show data accuracy is inefficiently under-supplied by a private provider. Solving the appropriate social planner{\textquoteright}s problem produces an implementable publication strategy. We implement the socially optimal publication plan for statistics on income and health status using data from the American Community Survey, National Health Interview Survey, Federal Statistical System Public Opinion Survey and Cornell National Social Survey. Our analysis indicates that welfare losses from providing too much privacy protection and, therefore, too little accuracy can be substantial.},
	owner = {vilhuber},
	timestamp = {2017.09.28},
	url = {http://digitalcommons.ilr.cornell.edu/ldi/37/},
}

@TechReport{VilhuberLagoze:LDI:2017,
	author = {Lars Vilhuber and Carl Lagoze},
	title = {Making Confidential Data Part of Reproducible Research},
	institution = {Labor Dynamics Institute, Cornell University},
	year = {2017},
	type = {Document},
	number = {41},
	owner = {vilhuber},
	timestamp = {2017.09.28},
	url = {http://digitalcommons.ilr.cornell.edu/ldi/41/},
}

@techreport{handle:1813:55761,
  author={Abowd, John M.},
  title={What Is a Privacy-Loss Budget and How Is It Used to Design Privacy Protection for a Confidential Database?},
  url={http://hdl.handle.net/1813/55761},
  type={Presentation},
  year={2018},
  institution={Presentations by the Labor Dynamics Institute},
  number={1813:55761},
  abstract={Webinar for Privacy Day 2018, Sponsored by the ASA Committee on Privacy and Confidentiality. For statistical agencies, the Big Bang event in disclosure avoidance occurred in 2003 when Irit Dinur and Kobbi Nissim, two well-known cryptographers, turned their attention to properties of safe systems for data publication from confidential sources. And the paradigm-shifting message was a very strong result showing that most of the confidentiality protection systems used by statistical agencies around the world, collectively known as statistical disclosure limitation, were not designed to defend against a database reconstruction attack. Such an attack recreates increasingly accurate record-level images of the confidential data as an agency publishes more and more accurate statistics from the same database. Why are we still talking about this theorem fifteen years later? What is required to modernize our disclosure limitation systems? The answer is recognizing that the database reconstruction theorem identified a real constraint on agency publication systems—there is only a finite amount of information in any confidential database. We can’t repeal that constraint. But it doesn’t help with the public-good mission of statistical agencies to publish data that are suitable for their intended uses. The hard work is incorporating the required privacy-loss budget constraint into the decision-making processes of statistical agencies. This means balancing the interests of data accuracy and privacy loss. A leading example of this process is the need for accurate redistricting data, to enforce the Voting Rights Act, and the protection of sensitive racial and ethnic information in the detailed data required for this activity. Wrestling with this tradeoff stares-down the database reconstruction theorem, and uses the formal privacy results that it inspired to specify the technologies. Specifying the decision framework for selecting a point on that technology has proven much more challenging. We still have a lot of work to do.},
}


@TechReport{RePEc:cen:wpaper:18-07,
  author={John M. Abowd and Ian M. Schmutte and Lars Vilhuber},
  title={{Disclosure Limitation and Confidentiality Protection in Linked Data}},
  year=2018,
  month=Jan,
  institution={Center for Economic Studies, U.S. Census Bureau},
  type={Working Papers},
  url={https://ideas.repec.org/p/cen/wpaper/18-07.html},
  number={18-07},
  abstract={Confidentiality protection for linked administrative data is a combination of access modalities and statistical disclosure limitation. We review traditional statistical disclosure limitation methods and newer methods based on synthetic data, input noise infusion and formal privacy. We discuss how these methods are integrated with access modalities by providing three detailed examples. The first example is the linkages in the Health and Retirement Study to Social Security Administration data. The second example is the linkage of the Survey of Income and Program Participation to administrative data from the Internal Revenue Service and the Social Security Administration. The third example is the Longitudinal Employer-Household Dynamics data, which links state unemployment insurance records for workers and firms to a wide variety of censuses and surveys at the U.S. Census Bureau. For examples, we discuss access modalities, disclosure limitation methods, the effectiveness of those methods, and the resulting analytical validity. The final sections discuss recent advances in access modalities for linked administrative data.},
  keywords={},
  doi={},
}

@TechReport{AbowdSchmutteVilhuber:LDI:2018,
author={John M. Abowd and Ian M. Schmutte and Lars Vilhuber},
title={{Disclosure Limitation and Confidentiality Protection in Linked Data}},
year=2018,
month=Jan,
Institution              = {Labor Dynamics Institute, Cornell University},
Year                     = {2018},
Type                     = {Document},
Number                   = {47},
Url                      = {http://digitalcommons.ilr.cornell.edu/ldi/47/},
abstract={Confidentiality protection for linked administrative data is a combination of access modalities and statistical disclosure limitation. We review traditional statistical disclosure limitation methods and newer methods based on synthetic data, input noise infusion and formal privacy. We discuss how these methods are integrated with access modalities by providing three detailed examples. The first example is the linkages in the Health and Retirement Study to Social Security Administration data. The second example is the linkage of the Survey of Income and Program Participation to administrative data from the Internal Revenue Service and the Social Security Administration. The third example is the Longitudinal Employer-Household Dynamics data, which links state unemployment insurance records for workers and firms to a wide variety of censuses and surveys at the U.S. Census Bureau. For examples, we discuss access modalities, disclosure limitation methods, the effectiveness of those methods, and the resulting analytical validity. The final sections discuss recent advances in access modalities for linked administrative data.},
keywords={},
doi={},
}
#### Rep archives
@Misc{RepArchive:abowd:schmutte:BPEA:2015,
  author = {Abowd, John M. and Schmutte, Ian M.},
  title  = {Replication Archive for: {E}conomic Analysis and Statistical Disclosure Limitation by {A}bowd and {S}chmutte (2015)},
  month  = aug,
  year   = {2015},
  doi    = {10.5281/zenodo.377008},
  url    = {https://doi.org/10.5281/zenodo.377008},
}

@Misc{RepArchive:Abowd:Revisiting:LDI:2018,
  author    = {Abowd, John M and Schmutte, Ian M},
  title     = {Replication archive for: {R}evisiting the economics of privacy: {P}opulation statistics and confidentiality protection as public goods},
  month     = 3,
  year      = {2018},
  note      = {Abowd acknowledges direct support from the U.S. Census Bureau and from NSF Grants BCS- 0941226, TC-1012593 and SES-1131848. Some of the research for this paper was conducted using the resources of the Social Science Gateway, which was partially supported by NSF grant SES-0922005. This paper was written while the first author was Distinguished Senior Research Fellow at the Census Bureau.},
  abstract  = {Replication archive for http://digitalcommons.ilr.cornell.edu/ldi/22/},
  doi       = {10.5281/zenodo.345385},
  owner     = {vilhuber},
  publisher = {Zenodo},
  timestamp = {2017.12.22},
  url      = {https://doi.org/10.5281/zenodo.345385},
}
@misc{RepArchive:Abowd:Privacy:LDI:2018,
  author    = {Abowd, John M. and Schmutte, Ian M.},
  title     = {Replication archive for: {A}n Economic Analysis of Privacy Protection and Statistical Accuracy as Social Choices},
  month     = 3,
  year      = {2018},
  doi       = {10.5281/zenodo.1208758},
  publisher = {Zenodo},
  url      = {https://doi.org/10.5281/zenodo.1208758},
}

### 2018 

@Article{Slavkovic2018,
  author    = {Aleksandra Slavkovi{\'{c}} and Lars Vilhuber},
  title     = {Remembering Stephen Fienberg},
  journal   = {Journal of Privacy and Confidentiality},
  year      = {2018},
  volume    = {8},
  number    = {1},
  month     = {dec},
  doi       = {10.29012/jpc.685},
  owner     = {vilhuber},
  publisher = {Journal of Privacy and Confidentiality},
  timestamp = {2019.03.10},
}

@Article{Vilhuber2018,
  author    = {Lars Vilhuber},
  title     = {Relaunching the Journal of Privacy and Confidentiality},
  journal   = {Journal of Privacy and Confidentiality},
  year      = {2018},
  volume    = {8},
  number    = {1},
  month     = {dec},
  doi       = {10.29012/jpc.706},
  owner     = {vilhuber},
  publisher = {Journal of Privacy and Confidentiality},
  timestamp = {2019.03.10},
}

@Article{AEAPP2019,
  author    = {John M. Abowd and Ian M. Schmutte and William N. Sexton and Lars Vilhuber},
  title     = {Why the Economics Profession Must Actively Participate in the Privacy Protection Debate},
  journal   = {AEA Papers and Proceedings},
  year      = {2019},
  volume    = {109},
  month     = {may},
  pages     = {397-402},
  doi       = {10.1257/pandp.20191106},
  owner     = {vilhuber},
  url       = {https://www.aeaweb.org/articles?id=10.1257/pandp.20191106},
  timestamp = {2019.03.10},
abstract = {When Google or the U.S. Census Bureau publish detailed statistics on browsing habits or neighborhood characteristics, some privacy is lost for everybody while supplying public information. To date, economists have not focused on the privacy loss inherent in data publication. In their stead, these issues have been advanced almost exclusively by computer scientists who are primarily interested in technical problems associated with protecting privacy. Economists should join the discussion, first, to determine where to balance privacy protection against data quality; a social choice problem. Furthermore, economists must ensure new privacy models preserve the validity of public data for economic research.},

}

@Article{AbowdSchmutte:Privacy:AER,
  author   = {John M. Abowd and Ian M. Schmutte},
  title    = {An Economic Analysis of Privacy Protection and Statistical Accuracy as Social Choices},
  journal  = {American Economic Review},
  year     = {2019},
  volume   = {109},
  number   = {1},
  pages    = {171-202},
  doi = {10.1257/aer.20170627},
  abstract = {Statistical agencies face a dual mandate to publish accurate statistics while protecting respondent privacy. Increasing privacy protection requires decreased accuracy. Recognizing this as a resource allocation problem, we propose an economic solution: operate where the marginal cost of increasing privacy equals the marginal benefit. Our model of production, from computer science, assumes data are published using an efficient differentially private algorithm. Optimal choice weighs the demand for accurate statistics against the demand for privacy. Examples from U.S.\ statistical programs show how our framework can guide decision-making. Further progress requires a better understanding of willingness-to-pay for privacy and statistical accuracy.},
  keywords = {Economics of Privacy, Formal Privacy, Statistical Disclosure Limitation, primary, background},
}

@InProceedings{NAP25305,
  author    = "Lars Vilhuber",
  title = "Making Confidential Data Part of Reproducible Research",
  editor    = "{National Academies of Sciences, Engineering, and Medicine} ",
  booktitle     = "Methods to Foster Transparency and Reproducibility of Federal Statistics: Proceedings of a Workshop",
  isbn      = "978-0-309-48629-3",
  doi       = "10.17226/25305",
  pages = "63-66",
  abstract  = "In 2014 the National Science Foundation (NSF) provided support to the National Academies of Sciences, Engineering, and Medicine for a series of Forums on Open Science in response to a government-wide directive to support increased public access to the results of research funded by the federal government. However, the breadth of the work resulting from the series precluded a focus on any specific topic or discussion about how to improve public access. Thus, the main goal of the Workshop on Transparency and Reproducibility in Federal Statistics was to develop some understanding of what principles and practices are, or would be, supportive of making federal statistics more understandable and reviewable, both by agency staff and the public. This publication summarizes the presentations and discussions from the workshop.",
  url       = "https://www.nap.edu/catalog/25305/methods-to-foster-transparency-and-reproducibility-of-federal-statistics-proceedings",
  year      = 2019,
  publisher = "The National Academies Press",
  address   = "Washington, DC",
  note = "National Academies of Sciences, Engineering, and Medicine; Michael Cohen (Rapporteur)",
}

@article{PrivPubGood,
author = {John M. Abowd and Ian M. Schmutte and William N. Sexton and Lars Vilhuber},
title = {Suboptimal Provision of Statistical Accuracy when it is a Public Good},
journal = {submitted},
year = {2019},
abstract = {With vast databases at their disposal, private tech companies can compete
with public statistical agencies as a source of population statistics.
However, private companies face different incentives to provide high-quality statistics and to protect the privacy of the people whose data are used. When both privacy protection and statistical accuracy are public goods,  private providers tend to produce at least one suboptimally, but it is not clear which. We model a firm that publishes statistics under a guarantee of differential privacy. We prove that provision by the private firm results in inefficiently low data quality in this framework.
}
}

@techreport{AbowdSchmutte:Privacy:LDI,
  author   = {John M. Abowd and Ian M. Schmutte},
  title    = {An Economic Analysis of Privacy Protection and Statistical Accuracy as Social Choices},
year=2018,
month=Aug,
Institution              = {Labor Dynamics Institute, Cornell University},
Year                     = {2018},
Type                     = {Document},
Number                   = {48},
Url                      = {http://digitalcommons.ilr.cornell.edu/ldi/48/},
abstract={Statistical agencies face a dual mandate to publish accurate statistics while protecting respondent privacy. Increasing privacy protection requires decreased accuracy. Recognizing this as a resource allocation problem, we propose an economic solution: operate where the marginal cost of increasing privacy equals the marginal benefit. Our model of production, from computer science, assumes data are published using an efficient differentially private algorithm. Optimal choice weighs the demand for accurate statistics against the demand for privacy. Examples from U.S.\ statistical programs show how our framework can guide decision-making. Further progress requires a better understanding of willingness-to-pay for privacy and statistical accuracy.},
  keywords = {Economics of Privacy, Formal Privacy, Statistical Disclosure Limitation, primary, background},
}

@techreport{LDI:AEAPP2019,
  author    = {John M. Abowd and Ian M. Schmutte and William N. Sexton and Lars Vilhuber},
  title     = {Why the Economics Profession Must Actively Participate in the Privacy Protection Debate},
year=2019,
month=Jan,
Institution              = {Labor Dynamics Institute, Cornell University},
Year                     = {2019},
Type                     = {Document},
Number                   = {51},
  url       = {https://digitalcommons.ilr.cornell.edu/ldi/51/},
  timestamp = {2019.03.10},
abstract = {When Google or the U.S. Census Bureau publish detailed statistics on browsing habits or neighborhood characteristics, some privacy is lost for everybody while supplying public information. To date, economists have not focused on the privacy loss inherent in data publication. In their stead, these issues have been advanced almost exclusively by computer scientists who are primarily interested in technical problems associated with protecting privacy. Economists should join the discussion, first, to determine where to balance privacy protection against data quality; a social choice problem. Furthermore, economists must ensure new privacy models preserve the validity of public data for economic research.},
  keywords = {Economics of Privacy, Formal Privacy, Statistical Disclosure Limitation, primary, background},

}

@article{ncrn-summary,
  author={Daniel H. Weinberg and John M. Abowd and Robert F. Belli and Noel Cressie and David C. Folch and Scott H. Holan and Margaret C. Levenstein and Kristen M. Olson and Jerome P. Reiter and Matthew D. Shapiro and Jolene Smyth and Leen-Kiat Soh and   Bruce D. Spencer and   Seth E. Spielman and   Lars Vilhuber and   Christopher K. Wikle},
  title={{Effects of a Government-Academic Partnership: Has the NSF-Census Bureau Research Network Helped Improve the U.S. Statistical System?}},
  year={2018},
  journal={Journal of Survey Statistics and Methodology},
  abstract={The National Science Foundation-Census Bureau Research Network (NCRN) was established in 2011 to create interdisciplinary research nodes on methodological questions of interest and significance to the broader research community and to the Federal Statistical System (FSS), particularly the Census Bureau. The activities to date have covered both fundamental and applied statistical research and have focused at least in part on the training of current and future generations of researchers in skills of relevance to surveys and alternative measurement of economic units, households, and persons. This paper discusses some of the key research findings of the eight nodes, organized into six topics: (1) Improving census and survey data collection methods; (2) Using alternative sources of data; (3) Protecting privacy and confidentiality by improving disclosure avoidance; (4) Using spatial and spatio-temporal statistical modeling to improve estimates; (5) Assessing data cost and quality tradeoffs; and (6) Combining information from multiple sources. It also reports on collaborations across nodes and with federal agencies, new software developed, and educational activities and outcomes. The paper concludes with an evaluation of the ability of the FSS to apply the NCRN’s research outcomes and suggests some next steps, as well as the implications of this research-network model for future federal government renewal initiatives.},
  keywords={},
  doi={10.1093/jssam/smy023},
}

### 2019
@TechReport{RePEc:cen:wpaper:19-13,
	author={Andrew Foote and Ashwin Machanavajjhala and Kevin McKinney},
	title={{Releasing Earnings Distributions using Differential Privacy: Disclosure Avoidance System For Post Secondary Employment Outcomes (PSEO)}},
	year=2019,
	month=Apr,
	institution={Center for Economic Studies, U.S. Census Bureau},
	type={Working Papers},
	url={https://ideas.repec.org/p/cen/wpaper/19-13.html},
	number={19-13},
	abstract={The U.S. Census Bureau recently released data on earnings percentiles of graduates from post secondary institutions. This paper describes and evaluates the disclosure avoidance system developed for these statistics. We propose a differentially private algorithm for releasing these data based on standard differentially private building blocks, by constructing a histogram of earnings and the application of the Laplace mechanism to recover a differentially-private CDF of earnings. We demonstrate that our algorithm can release earnings distributions with low error, and our algorithm out-performs prior work based on the concept of smooth sensitivity from Nissim, Raskhodnikova and Smith (2007).},
	keywords={},
}

@Article{FooteAshwinMcKinney:JPC:2019,
	author={Andrew Foote and Ashwin Machanavajjhala and Kevin McKinney},
	title={{Releasing Earnings Distributions using Differential Privacy: Disclosure Avoidance System For Post Secondary Employment Outcomes (PSEO)}},
	year=2019,
	abstract={The U.S. Census Bureau recently released data on earnings percentiles of graduates from post secondary institutions. This paper describes and evaluates the disclosure avoidance system developed for these statistics. We propose a differentially private algorithm for releasing these data based on standard differentially private building blocks, by constructing a histogram of earnings and the application of the Laplace mechanism to recover a differentially-private CDF of earnings. We demonstrate that our algorithm can release earnings distributions with low error, and our algorithm out-performs prior work based on the concept of smooth sensitivity from Nissim, Raskhodnikova and Smith (2007).},
	journal   = {Journal of Privacy and Confidentiality},
	volume    = {submitted},
	publisher = {Journal of Privacy and Confidentiality},
	}

@techreport{privacyprimer2019,
	author       = {John Abowd and
	Ian Schmutte and
	William Sexton and
	Lars Vilhuber},
	title        = {Introductory Readings in Formal Privacy for  Economists},
	grantnote         = {{Supported by Alfred P. Sloan Foundation Grant 
	G-2015-13903 and NSF Grant SES-1131848}},
	month        = apr,
	year         = 2019,
	type = {Preprint},
	note = {Available online at \url{https://labordynamicsinstitute.github.io/privacy-bibliography/}},
	doi          = {10.5281/zenodo.2621344},
	url          = {https://doi.org/10.5281/zenodo.2621344}
}